{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import argparse\n",
    "from collections import OrderedDict\n",
    "#sys\n",
    "#from saltseg.models import salt_models\n",
    "sys.path.append(\"/pdata/pdata27/T_DATA_ANALYTICS/Src/FaultNet\")  ## include path of FautNet\n",
    "import time\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We use the 20 images in data/TestSet as a pure hold-out test set for iou comparison\n",
    " Note:\n",
    " 1. Wu's model (Geophysics, 2019) used this images as validation set. But we still show them here and will show higher iou when these images are used as a pure holdout test-set by our models. For all our models (vnet and unet_res*) these 20 images are never used in training or validation but set-aside for pure test-set.\n",
    " \n",
    " 2. iou computation and prediction scripts for our models are included here\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeiou(preds, actuals):\n",
    "    preds = preds>0.5\n",
    "    actuals = actuals>0.5\n",
    "    intersection = actuals & preds\n",
    "    union = actuals | preds\n",
    "    \n",
    "    return intersection.sum()/(union.sum()+1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions using vnet or unet_res1. Do the following:\n",
    "Set path to test images and models correctly to run. \n",
    "Assumes your machine has GPUs. Note models provided here are trained after wrapping with DataParallel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=\"/pdata/pdata27/T_DATA_ANALYTICS/FAULT/SEN_MODELS/unet3d_wu_Noiter_NoiternetChain2_CE3D/UNET3D_WU_ITERCHAIN_2020_01_04_249.pkl\"\n",
    "model_arch=\"unet_3d_res1\" #\"vnet\"   ## model architecture tag : vnet or unet_res1\n",
    "test_image_dir=\"/pdata/pdata27/T_DATA_ANALYTICS/Src/FaultNet/data/TestSet/images/\"  # path to test images in TestSet\n",
    "test_label_dir=\"/pdata/pdata27/T_DATA_ANALYTICS/Src/FaultNet/data/TestSet/labels/\"  # path to test labels in TestSet\n",
    "wu_pred_dir=\"/pdata/pdata27/T_DATA_ANALYTICS/Src/FaultNet/data/Predictions/WU_model/\"   # path to preds from the wu model\n",
    "output_dir=\"/pdata/pdata27/T_DATA_ANALYTICS/Src/FaultNet/data/VNetPreds/\"  ## write model prediction here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preds(modelin, image_folder, label_folder, wu_folder, out_folder,save_flag=False):\n",
    "    \"\"\"\n",
    "    make predictions on images in the image folder and write out to out_folder\n",
    "    compute iou for each image and compare to the iou of predictions mad by the wu-model\n",
    "    \"\"\"\n",
    "    toc=time.time(); count_files=0\n",
    "    for files in os.listdir(image_folder):\n",
    "        filename, ext = os.path.splitext(files)\n",
    "        image_file = os.path.join(image_folder, filename) +\".npy\"\n",
    "        label_file = os.path.join(label_folder, filename) +\".npy\"\n",
    "        wu_file = os.path.join(wu_folder, filename) +\".npy\"\n",
    "\n",
    "        image_load = np.load(image_file)\n",
    "        label_load = np.load(label_file)\n",
    "        wu_pred = np.load(wu_file); wu_pred[wu_pred>=0.9]=1; wu_pred[wu_pred!=1]=0\n",
    "\n",
    "        label_load = label_load.transpose(2,1,0) # Z, X, Y\n",
    "        wu_pred = wu_pred.transpose(2,1,0)       # Z, X, Y\n",
    "\n",
    "        image_load = (image_load - np.mean(image_load))/np.std(image_load)  # normalization used in training\n",
    "        image_load = image_load.transpose(2,1,0)  # Z, X, Y\n",
    "        image_load = np.expand_dims(np.expand_dims(image_load,0),0)  # 1,1,Z,X,Y (B,C,Z,X,Y)\n",
    "        with torch.no_grad():\n",
    "            image_tensor = torch.from_numpy(image_load).float().cuda()\n",
    "            output = modelin(image_tensor)\n",
    "        logits = output['logits']\n",
    "        \n",
    "        #log_preds1 = F.softmax(logits, dim=1)\n",
    "        #log_preds1_numpy = log_preds1.data.cpu().numpy()\n",
    "        #log_preds1_numpy = log_preds1_numpy[0,:,:,:,:]\n",
    "        #pred_argmax = np.argmax(log_preds1_numpy, axis=0).astype(np.float32)\n",
    "        \n",
    "        probits = F.softmax(logits,dim=1).data.cpu().numpy()\n",
    "        pred_argmax =  np.argmax(probits[0,:,:,:,:], axis=0).astype(np.float32)\n",
    "        iou_preds = computeiou(pred_argmax,label_load)\n",
    "        iou_wu = computeiou(wu_pred,label_load)\n",
    "        print(\" ---- for filename %s iou preds: %f wu-model: %f ----\"%(filename,iou_preds,iou_wu))\n",
    "        if save_flag==True:\n",
    "            output_file = os.path.join(out_folder,filename)+\".npy\"\n",
    "            np.save(output_file, pred_argmax.transpose(2,1,0)) # save in X,Y,Z format same as test labels/images\n",
    "        count_files +=1\n",
    "    tic=time.time()\n",
    "    print(\" Done prediction for %d files in %f s\" %(count_files, tic-toc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load model, run predictions on one gpu (specified as gpu:0 here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " model arch specified by user is  unet_3d_res1\n",
      "loading UNet3d with 1 Residual block, output will have 2 channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pdata/pdata27/T_DATA_ANALYTICS/Src/FaultNet/models/networks_other.py:42: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n"
     ]
    }
   ],
   "source": [
    "gpu_use=\"0\"\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_use\n",
    "\n",
    "from models import load_models\n",
    "model=load_models.getModel(model_arch=model_arch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove dataparallel from model dict as models will be used on single gpu for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dict=torch.load(model_path, map_location=lambda storage, loc: storage)['model_state']\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in curr_dict.items():\n",
    "    name = k[7:]\n",
    "    new_state_dict[name] = v\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unet_3D_Res1(\n",
       "  (dropout): Dropout3d(p=0.6)\n",
       "  (lrelu): LeakyReLU(negative_slope=0.01, inplace)\n",
       "  (conv0_1): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (conv0_2): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (conv0_3): Sequential(\n",
       "    (0): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (1): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    (2): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  )\n",
       "  (inorm0): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "  (conv1): BasicRes(\n",
       "    (conv1): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "    (norm_relu_conv): Sequential(\n",
       "      (0): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (1): LeakyReLU(negative_slope=0.01, inplace)\n",
       "      (2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    )\n",
       "    (dropout): Dropout3d(p=0.6)\n",
       "    (inorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (lrelu): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    (last_layer_op): Sequential(\n",
       "      (0): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (1): LeakyReLU(negative_slope=0.01, inplace)\n",
       "      (2): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (3): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (4): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (5): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    )\n",
       "  )\n",
       "  (conv2): BasicRes(\n",
       "    (conv1): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "    (norm_relu_conv): Sequential(\n",
       "      (0): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (1): LeakyReLU(negative_slope=0.01, inplace)\n",
       "      (2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    )\n",
       "    (dropout): Dropout3d(p=0.6)\n",
       "    (inorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (lrelu): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    (last_layer_op): Sequential(\n",
       "      (0): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (1): LeakyReLU(negative_slope=0.01, inplace)\n",
       "      (2): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (4): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (5): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    )\n",
       "  )\n",
       "  (conv3): BasicRes(\n",
       "    (conv1): Conv3d(64, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "    (norm_relu_conv): Sequential(\n",
       "      (0): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (1): LeakyReLU(negative_slope=0.01, inplace)\n",
       "      (2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    )\n",
       "    (dropout): Dropout3d(p=0.6)\n",
       "    (inorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (lrelu): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    (last_layer_op): Sequential(\n",
       "      (0): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (1): LeakyReLU(negative_slope=0.01, inplace)\n",
       "      (2): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (4): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (5): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    )\n",
       "  )\n",
       "  (conv_up1): BasicDecoder(\n",
       "    (baseconv): Sequential(\n",
       "      (0): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    )\n",
       "    (conv1x1): Conv3d(320, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (upconv): Sequential(\n",
       "      (0): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (1): LeakyReLU(negative_slope=0.01, inplace)\n",
       "      (2): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (4): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (5): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    )\n",
       "    (upconv_lastlayer): Sequential(\n",
       "      (0): Conv3d(320, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    )\n",
       "  )\n",
       "  (conv_up2): BasicDecoder(\n",
       "    (baseconv): Sequential(\n",
       "      (0): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    )\n",
       "    (conv1x1): Conv3d(96, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (upconv): Sequential(\n",
       "      (0): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (1): LeakyReLU(negative_slope=0.01, inplace)\n",
       "      (2): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (3): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (4): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (5): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    )\n",
       "    (upconv_lastlayer): Sequential(\n",
       "      (0): Conv3d(96, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    )\n",
       "  )\n",
       "  (conv_up3): BasicDecoder(\n",
       "    (baseconv): Sequential(\n",
       "      (0): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    )\n",
       "    (conv1x1): Conv3d(48, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (upconv): Sequential(\n",
       "      (0): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (1): LeakyReLU(negative_slope=0.01, inplace)\n",
       "      (2): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (3): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (4): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (5): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    )\n",
       "    (upconv_lastlayer): Sequential(\n",
       "      (0): Conv3d(48, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace)\n",
       "    )\n",
       "  )\n",
       "  (final1): Conv3d(16, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(new_state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set folder path where preds will be written out. Each pred will be written out with the same filename as the test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ---- for filename 0 iou preds: 0.764095 wu-model: 0.695840 ----\n",
      " ---- for filename 10 iou preds: 0.788676 wu-model: 0.706450 ----\n",
      " ---- for filename 11 iou preds: 0.703346 wu-model: 0.632799 ----\n",
      " ---- for filename 12 iou preds: 0.664703 wu-model: 0.609656 ----\n",
      " ---- for filename 13 iou preds: 0.555531 wu-model: 0.493070 ----\n",
      " ---- for filename 14 iou preds: 0.658020 wu-model: 0.598125 ----\n",
      " ---- for filename 15 iou preds: 0.622319 wu-model: 0.561113 ----\n",
      " ---- for filename 16 iou preds: 0.683888 wu-model: 0.652235 ----\n",
      " ---- for filename 17 iou preds: 0.737977 wu-model: 0.672268 ----\n",
      " ---- for filename 18 iou preds: 0.671623 wu-model: 0.576642 ----\n",
      " ---- for filename 19 iou preds: 0.625399 wu-model: 0.529391 ----\n",
      " ---- for filename 1 iou preds: 0.750731 wu-model: 0.701766 ----\n",
      " ---- for filename 2 iou preds: 0.821693 wu-model: 0.774017 ----\n",
      " ---- for filename 3 iou preds: 0.737561 wu-model: 0.686416 ----\n",
      " ---- for filename 4 iou preds: 0.661090 wu-model: 0.622698 ----\n",
      " ---- for filename 5 iou preds: 0.693249 wu-model: 0.611119 ----\n",
      " ---- for filename 6 iou preds: 0.749878 wu-model: 0.651379 ----\n",
      " ---- for filename 7 iou preds: 0.722503 wu-model: 0.630577 ----\n",
      " ---- for filename 8 iou preds: 0.743650 wu-model: 0.697638 ----\n",
      " ---- for filename 9 iou preds: 0.649624 wu-model: 0.598222 ----\n",
      " Done prediction for 20 files in 5.047534 s\n"
     ]
    }
   ],
   "source": [
    "save_flag=False  # if set to true preds will be saved in output_dir\n",
    "make_preds(model, test_image_dir, test_label_dir, wu_pred_dir, output_dir, save_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
